input {
  # Filebeat input for general logs
  beats {
    port => 5044
    type => "beats"
  }
  
  # Direct file input for MLflow logs
  file {
    path => "/app/logs/mlflow.log"
    start_position => "beginning"
    type => "mlflow_logs"
    codec => "plain"
  }
  
  # Heartbeat for monitoring
  heartbeat {
    interval => 30
    type => "heartbeat"
  }
}

filter {
  # Handle MLflow specific logs
  if [type] == "mlflow_logs" {
    # Parse the message field to extract MLFLOW_EVENT logs
    if [message] =~ /MLFLOW_EVENT:/ {
      grok {
        match => { "message" => "MLFLOW_EVENT: %{GREEDYDATA:event_json}" }
      }
      
      # Parse the JSON event data
      json {
        source => "event_json"
        target => "mlflow_event"
      }
      
      # Add pipeline metadata
      mutate {
        add_field => {
          "pipeline" => "mlflow"
          "log_level" => "INFO"
          "logger_name" => "mlflow_app"
        }
      }
      
      # Extract specific event types for easier filtering
      if [mlflow_event][event_type] {
        mutate {
          add_field => { "event_category" => "%{[mlflow_event][event_type]}" }
        }
      }
      
      # Add timestamp from the event if available
      if [mlflow_event][timestamp] {
        date {
          match => [ "mlflow_event.timestamp", "ISO8601" ]
          target => "@timestamp"
        }
      }
    }
    
    # For regular log messages (non-MLFLOW_EVENT)
    else {
      grok {
        match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:name} %{GREEDYDATA:log_message}" }
      }
      
      mutate {
        add_field => {
          "pipeline" => "mlflow"
          "event_category" => "general_log"
        }
      }
    }
  }
  
  # Handle beats input (general logs)
  if [type] == "beats" {
    mutate {
      add_field => { "pipeline" => "general" }
    }
    
    # Parse JSON logs if they exist
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
        target => "parsed_log"
      }
    }
  }
  
  # Handle heartbeat
  if [type] == "heartbeat" {
    mutate {
      add_field => {
        "pipeline" => "monitoring"
        "event_category" => "heartbeat"
      }
    }
  }
  
  # Common processing for all log types
  mutate {
    add_field => {
      "environment" => "mlops"
      "service" => "mlflow_pipeline"
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "changeme"
    template_name => "logs"
    template => {
      "index_patterns" => ["logs-*"]
      "settings" => {
        "number_of_shards" => 1
        "number_of_replicas" => 0
      }
      "mappings" => {
        "properties" => {
          "@timestamp" => { "type" => "date" }
          "pipeline" => { "type" => "keyword" }
          "event_category" => { "type" => "keyword" }
          "log_level" => { "type" => "keyword" }
          "service" => { "type" => "keyword" }
          "environment" => { "type" => "keyword" }
          "mlflow_event" => { "type" => "object" }
        }
      }
    }
  }
  
  # Debug output to console
  stdout {
    codec => rubydebug
  }
} 