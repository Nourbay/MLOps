input {
  file {
    path => "/app/logs/mlflow.log"
    start_position => "beginning"
    codec => "json"
    type => "mlflow_logs"
  }
}

filter {
  if [type] == "mlflow_logs" {
    # Parse the message field to extract MLFLOW_EVENT logs
    if [message] =~ /MLFLOW_EVENT:/ {
      grok {
        match => { "message" => "MLFLOW_EVENT: %{GREEDYDATA:event_json}" }
      }
      
      # Parse the JSON event data
      json {
        source => "event_json"
        target => "mlflow_event"
      }
      
      # Add pipeline metadata
      mutate {
        add_field => {
          "pipeline" => "mlflow"
          "log_level" => "%{[level]}"
          "logger_name" => "%{[name]}"
        }
      }
      
      # Extract specific event types for easier filtering
      if [mlflow_event][event_type] {
        mutate {
          add_field => { "event_category" => "%{[mlflow_event][event_type]}" }
        }
      }
      
      # Add timestamp from the event if available
      if [mlflow_event][timestamp] {
        date {
          match => [ "mlflow_event.timestamp", "ISO8601" ]
          target => "@timestamp"
        }
      }
    }
    
    # For regular log messages (non-MLFLOW_EVENT)
    else {
      mutate {
        add_field => {
          "pipeline" => "mlflow"
          "event_category" => "general_log"
        }
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "mlflow-logs-%{+YYYY.MM.dd}"
    document_type => "mlflow_log"
    user => "elastic"
    password => "changeme"
  }
  
  # Also output to console for debugging
  stdout {
    codec => rubydebug
  }
} 